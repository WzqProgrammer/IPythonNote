{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.酒店评论情感分析\n",
    "我们这里解决的问题，是一个具体场景下的性感分析，准确一点说，是我们想借助自然语言处理对文本的情感分类能力，自动对酒店评论数据进行情感分析，进而可以借助情感分析的结果完成酒店的筛选。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据读取\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import jieba\n",
    "import numpy as np\n",
    "import codecs  ##codecs提供的open方法来指定打开的文件的语言编码，它会在读取的时候自动转换为内部unicode \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        stopwords.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 评论数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def get_content(fullname):\n",
    "    f = codecs.open(fullname, 'r', encoding='gbk', errors='ignore')\n",
    "    lines = []\n",
    "    \n",
    "    for eachline in f.readlines():\n",
    "        eachline = eachline.strip()\n",
    "        \n",
    "        if eachline:  # 当前行不为空\n",
    "            lines.append(eachline)\n",
    "    f.close()\n",
    "    return lines\n",
    "\n",
    "# 需处理的数据路径\n",
    "inp = 'E:\\下载\\senti_analysis-master\\data\\ChnSentiCorp_htl_ba_2000'\n",
    "folders = ['neg', 'pos']\n",
    "for foldername in folders:\n",
    "    outp = '1000_' + foldername + '.txt'   # 输出文件\n",
    "    output = codecs.open(outp, 'w')\n",
    "    \n",
    "    rootdir= os.path.join(inp, foldername)\n",
    "    for each_file in os.listdir(rootdir):\n",
    "        contents = get_content(os.path.join(rootdir, each_file))\n",
    "        output.write(''.join(contents)+'\\n')\n",
    "        \n",
    "    output.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 读取评论数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\WANGZH~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.635 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "def read_file(in_f, sentiment, stopwords, words, sentences):\n",
    "    with open(in_f, 'r', encoding='gbk') as f:\n",
    "        for line in f.readlines():\n",
    "            try:\n",
    "                segs = jieba.lcut(line.strip())\n",
    "                # 停用词过滤\n",
    "                segs = [word for word in segs if word not in stopwords and len(word)>1]\n",
    "                # 记录词语\n",
    "                words.extend(segs)\n",
    "                # 添加（分词评论，情感）的元组\n",
    "                sentences.append((segs, sentiment))\n",
    "            except:\n",
    "                print(line)\n",
    "                continue\n",
    "                \n",
    "# 读取数据\n",
    "words = []\n",
    "sentences = []\n",
    "# 好评数据\n",
    "sentiment = 1\n",
    "read_file('1000_pos.txt', 1, stopwords, words, sentences)\n",
    "\n",
    "# 差评数据\n",
    "sentiment = 0\n",
    "read_file('1000_neg.txt', 0, stopwords, words, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['距离', '川沙', '公路', '较近', '公交', '指示', '蔡陆线', '麻烦', '建议', '路线']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['距离', '川沙', '公路', '较近', '公交', '指示', '蔡陆线', '麻烦', '建议', '路线', '房间', '较为简单'],\n",
       "  1),\n",
       " (['商务', '大床', '房间', '很大', '床有', '2M', '整体', '感觉', '经济', '实惠', '不错'], 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>评论词语</th>\n",
       "      <th>计数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10533</td>\n",
       "      <td>酒店</td>\n",
       "      <td>2741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5629</td>\n",
       "      <td>房间</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6779</td>\n",
       "      <td>服务</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7373</td>\n",
       "      <td>没有</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>入住</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1235</td>\n",
       "      <td>不错</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7186</td>\n",
       "      <td>比较</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>前台</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5489</td>\n",
       "      <td>感觉</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10930</td>\n",
       "      <td>非常</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6462</td>\n",
       "      <td>早餐</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>一个</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6098</td>\n",
       "      <td>携程</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9709</td>\n",
       "      <td>设施</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6783</td>\n",
       "      <td>服务员</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4445</td>\n",
       "      <td>宾馆</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6319</td>\n",
       "      <td>方便</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4386</td>\n",
       "      <td>客人</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1828</td>\n",
       "      <td>价格</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6582</td>\n",
       "      <td>晚上</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      评论词语    计数\n",
       "10533   酒店  2741\n",
       "5629    房间  1899\n",
       "6779    服务   950\n",
       "7373    没有   875\n",
       "2225    入住   764\n",
       "1235    不错   758\n",
       "7186    比较   552\n",
       "2675    前台   509\n",
       "5489    感觉   498\n",
       "10930   非常   497\n",
       "6462    早餐   485\n",
       "635     一个   474\n",
       "6098    携程   455\n",
       "9709    设施   435\n",
       "6783   服务员   432\n",
       "4445    宾馆   382\n",
       "6319    方便   375\n",
       "4386    客人   336\n",
       "1828    价格   321\n",
       "6582    晚上   282"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = pd.DataFrame({'评论词语':words})\n",
    "words_stat = words_df.groupby(by=['评论词语'])['评论词语'].agg({'计数':np.size})\n",
    "words_stat = words_stat.reset_index().sort_values(by=['计数'], ascending=False)\n",
    "words_stat.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.机器学习解决方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分数据\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences)\n",
    "x = [' '.join(sentence) for sentence in x]\n",
    "# 数据集划分\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)  # 1800条评论作为训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['酒店 比较 房间 还好 酒店 市中心 但离 出差 公司 较近 几次',\n",
       " '第二次 入住 客户 很近 图个 方便 先说 第一次 入住 空调 不冷 房间 桑拿房 归类 运气 问题 略过 不计 网络 速度慢 只能 不可思议 形容 中国电信 宽频 服务 酒店 速度 拨号上网 还慢 算是 眼界 第二次 checkin 就让 决定 酒店 第三次 前台 男员工 吊儿郎当 不说 一副 爱理不理 腔调 三句话 勉强 几个 搞不好 老板 儿子 想不出 酒店 这种 员工 原因 何在 早餐 烹饪 厨师 知道 教育 躲来躲去 想下 一碗 半天 硬是 不到 后面 服务台 小姐 索性 装作 看到 估计 希望 多一事不如少一事 房间 设备 这次 正常 赶走 一个 客人 轻而易举 办法 发现 管理 适用 员工 酒店 管理 问题 只能 酒店 觉得 根本 不想 做个 四星级 酒店 吹毛求疵 道歉 绝大多数 兢兢业业 员工 表示歉意',\n",
       " '洒店 房间 太小 设计 不合理 电梯 三十 几层楼 两个 电梯 早餐 需先到 三楼 一条 长廊 电梯 37 一次 电梯 最少 要花 分钟 价格 偏贵 早餐 宽带 费用 五星级 酒店 宾馆 反馈 2008 25 需要 更正 酒店 总共 29 早餐 27 电梯 一共 三个 房间 大小 区别 这次 所住 比较 宽带 08 已经 宽带 免费 给予 携程 用户 含早 优惠 希望 继续 支持']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征抽取\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    ngram_range=(1,2),    # 使用长度为1和2的ngram\n",
    "    max_features=1000,    # 保留最高频的1000个ngrams\n",
    ")\n",
    "vec.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB   # 使用朴素贝叶斯\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec.transform(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(x_test), y_test)  # 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以换成其他的分类器，如逻辑斯蒂回归、SVM等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.深度学习解决方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(nb_words = 2500, split=' ')\n",
    "tokenizer.fit_on_texts(x)\n",
    "X = tokenizer.texts_to_sequences(x)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 336s 187ms/step - loss: 0.7784 - accuracy: 0.5339\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 401s 223ms/step - loss: 0.7421 - accuracy: 0.4983\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 406s 225ms/step - loss: 0.6836 - accuracy: 0.5372\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 411s 228ms/step - loss: 0.6345 - accuracy: 0.6461\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 410s 228ms/step - loss: 0.5739 - accuracy: 0.6972\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 424s 236ms/step - loss: 0.4451 - accuracy: 0.8167\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 465s 258ms/step - loss: 0.3576 - accuracy: 0.8461\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 452s 251ms/step - loss: 0.2963 - accuracy: 0.8772\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 458s 255ms/step - loss: 0.2244 - accuracy: 0.9172\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 496s 275ms/step - loss: 0.2415 - accuracy: 0.8972\n",
      "LogLoss损失：0.52\n",
      "验证集的准确率：0.80\n"
     ]
    }
   ],
   "source": [
    "# 设定embedding维度等超参数\n",
    "embed_dim = 16\n",
    "lstm_out = 1000\n",
    "batch_size = 32   # 以32个样本为一组\n",
    "\n",
    "# 构建LSTM网络完成感情分析\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500, embed_dim, input_length=X.shape[1], dropout=0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# 设置损失函数、优化器和评估标准\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 显示训练进程\n",
    "Y = pd.get_dummies(pd.DataFrame({'label':[str(target) for target in y]})).values\n",
    "# 数据集拆分\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size = 0.1, random_state=2018)\n",
    "\n",
    "# 拟合与训练模型\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=10)\n",
    "\n",
    "# 结果评估\n",
    "score, acc = model.evaluate(X_valid, Y_valid, verbose=2, batch_size=batch_size)\n",
    "print(\"LogLoss损失：%.2f\"%(score))\n",
    "print(\"验证集的准确率：%.2f\"%(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\Models\\my_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss损失：0.52\n",
      "验证集的准确率：0.80\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('D:\\Models\\my_model_1.h5')\n",
    "\n",
    "score, acc = model2.evaluate(X_valid, Y_valid, verbose=2, batch_size=batch_size)\n",
    "print(\"LogLoss损失：%.2f\"%(score))\n",
    "print(\"验证集的准确率：%.2f\"%(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于训练数据集很少，机器学习和深度学习的模型差距不大，后续任务是爬取更多的酒店数据，同时对比模型的准确率，最终通过一个合适的模型判别一个酒店所有的评论好坏，统计真正的好评率，因为存在打的星与实际评论不符的情况，同时还可以统计一片区域的酒店评论情况，这些是数据分析的内容，做不做随意。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
