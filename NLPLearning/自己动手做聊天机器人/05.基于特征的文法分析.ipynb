{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、语法和文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(S\n",
    "    (NP  小明)\n",
    "    (VP\n",
    "        (V 追赶\n",
    "        (NP \n",
    "            (Det 一只)\n",
    "            (N 兔子)\n",
    "        )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里面的N表示名词，Det表示限定词，NP表示名词短语，V表示动词，VP表示动词短语，S表示句子\n",
    "这种句子分析方法叫做语法分析  \n",
    "因为句子可以无限组合无限扩展，所以单纯用语法分析来完成自然语言处理这件事情是不可能的，所以出现了文法分析  \n",
    "文法是一个潜在的无限的句子集合的一个紧凑的特性，它是通过一组形式化模型来表示的，文法可以覆盖所有结构的句子，对一个句子做文法分析，就是把句子往文法模型上靠，如果同时符合多种文法，那就是有歧义的句子  \n",
    "最重要的结论：文法结构范围相当广泛，无法用规则类的方法来处理，只有利用基于特征的方法才能处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、文法特征结构\n",
    "文法特征举例：单词最后一个字母、词性标签、文法类别、正字拼写、指示物、关系、施事角色、受事角色  \n",
    "因为文法特征是一种kv，所以特征结构的存储形式是字典  \n",
    "不是什么样的句子都能提取出每一个文法特征的，需要满足一定的条件，这需要通过一系列的检查手段来达到，包括：句法协议（比如this dog就是对的，而these dog就是错的）、属性和约束、术语"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、特征结构处理\n",
    "nltk帮我们实现了特征结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NUM   = 'sg'   ]\n",
      "[ TENSE = 'past' ]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "fs1 = nltk.FeatDict(TENSE='past', NUM='sg')\n",
    "print(fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在nltk的库里已经有了一些产生式文法描述可以直接使用  \n",
    "我们看其中最简单的一个sql0.fcfg，这是一个查找国家城市的sql语句的文法："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% start S\n",
    "\n",
    "S[SEM=(?np + WHERE + ?vp)] -> NP[SEM=?np] VP[SEM=?vp]\n",
    "\n",
    "VP[SEM=(?v + ?pp)] -> IV[SEM=?v] PP[SEM=?pp]\n",
    "VP[SEM=(?v + ?ap)] -> IV[SEM=?v] AP[SEM=?ap]\n",
    "NP[SEM=(?det + ?n)] -> Det[SEM=?det] N[SEM=?n]\n",
    "PP[SEM=(?p + ?np)] -> P[SEM=?p] NP[SEM=?np]\n",
    "AP[SEM=?pp] -> A[SEM=?a] PP[SEM=?pp]\n",
    "\n",
    "NP[SEM='Country=\"greece\"'] -> 'Greece'\n",
    "NP[SEM='Country=\"china\"'] -> 'China'\n",
    "\n",
    "Det[SEM='SELECT'] -> 'Which' | 'What'\n",
    "\n",
    "N[SEM='City FROM city_table'] -> 'cities'\n",
    "\n",
    "IV[SEM=''] -> 'are'\n",
    "A[SEM=''] -> 'located'\n",
    "P[SEM=''] -> 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解释一下\n",
    "这里面从上到下是从最大范围到最小范围一个个的解释，S是句子  \n",
    "我们来加载这个文法描述，并试验如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import load_parser\n",
    "\n",
    "cp = load_parser('sql0.fcfg')\n",
    "query = 'What cities are located are located in China'\n",
    "tokens = query.split()\n",
    "for tree in cp.parse(tokens=tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
