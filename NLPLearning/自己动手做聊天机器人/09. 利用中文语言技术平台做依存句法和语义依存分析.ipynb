{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、概念介绍\n",
    "### 1.1 依存句法分析  \n",
    "句法就是句子的法律规则，也就是句子里成分都是按照什么法律规则组织在一起的。而依存句法就是这些成分之间有一种依赖关系。什么是依赖：没有你的话，我存在就是个错误。“北京是中国的首都”，如果没有“首都”，那么“中国的”存在就是个错误，因为“北京是中国的”表达的完全是另外一个意思了。  \n",
    "<br/> \n",
    "### 1.2 语义依存分析\n",
    "“语义”就是说句子的含义，“张三昨天告诉李四一个秘密”，那么语义包括：谁告诉李四秘密的？张三。张三告诉谁一个秘密？李四。张三什么时候告诉的？昨天。张三告诉李四什么？秘密。  \n",
    "<br/> \n",
    "### 1.3 语义依存和依存句法的区别\n",
    "依存句法强调介词、助词等的划分作用，语义依存注重实词之间的逻辑关系  \n",
    "另外，依存句法随着字面词语变化而不同，语义依存不同字面词语可以表达同一个意思，句法结构不同的句子语义关系可能相同。  \n",
    "<br/> \n",
    "### 1.4 对聊天机器人的意义\n",
    "依存句法分析和语义分析相结合使用，对对方说的话进行依存和语义分析后，一方面可以让计算机理解句子的含义，从而匹配到最合适的回答，另外如果有已经存在的依存、语义分析结果，还可以通过置信度匹配来实现聊天回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、依存句法分析\n",
    "[详细解释链接](https://blog.csdn.net/weixin_42936560/article/details/81702169)  \n",
    "依存句法分析的基本任务是确定句式的句法结构(短语结构)或句子中词汇之间的依存关系。依存句法分析最重要的两棵树：  \n",
    "* 依存树：子节点依存于父节点\n",
    "* 依存投射树：实线表示依存联结关系，位置低的成分依存于位置高的成分，虚线为投射线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![依存树与依存投射树](Images/句法分析.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 依存关系的五条公理\n",
    "* 1. 一个句子中只有一个成分是独立的  \n",
    "<br/> \n",
    "* 2. 其他成分直接依存于某一成分  \n",
    "<br/> \n",
    "* 3. 任何一个成分都不能依存于两个或两个以上的成分  \n",
    "<br/> \n",
    "* 4. 如果A成分直接依存于B成分，而C成分在句子中位于A和B之间，那么C或者直接依存于B，或者直接依存于A和B之间的某一成分  \n",
    "<br/> \n",
    "* 5. 中心成分左右两面的其他成分相互不发生关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LTP依存关系标记\n",
    "![LTP](Images/LTP依存关系标记.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依存关系通过机器学习和人工标注来完成，机器学习依赖人工标注，分词词性、依存树库、语义角色都需要做人工标注，有了这写人工标注之后，就可以做机器学习来分析新的句子的依存句法了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LTP云平台\n",
    "使用科大讯飞的LTP平台，[平台链接]()，[使用文档链接](https://www.xfyun.cn/doc/nlp/dependencyParsing/API.html#%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E)  \n",
    "接入平台服务，使用实例如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"code\":\"0\",\"data\":{\"pos\":[\"n\",\"n\",\"n\",\"wp\",\"v\",\"m\",\"v\",\"wp\",\"nh\",\"v\",\"b\",\"d\",\"v\",\"wp\",\"v\",\"p\",\"n\",\"wp\",\"i\",\"a\",\"v\",\"wp\",\"nt\",\"v\",\"p\",\"n\",\"nh\",\"wp\"]},\"desc\":\"success\",\"sid\":\"ltp0004987c@dx0d4010e8c7d8a00100\"}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import base64\n",
    "\n",
    "# 接口地址，使用的是中文分词服务\n",
    "url = \"http://ltpapi.xfyun.cn/v1/cws\"\n",
    "# 使用词性标注服务\n",
    "#url = \"http://ltpapi.xfyun.cn/v1/pos\"\n",
    "\n",
    "# 开发平台应用ID\n",
    "x_appid = \"5d8d614f\"\n",
    "# 开发平台接口密钥\n",
    "api_key = \"0266c5f310c77b20a2814937525358c5\"\n",
    "# 语言文本\n",
    "TEXT=\"汉皇重色思倾国，御宇多年求不得。杨家有女初长成，养在深闺人未识。天生丽质难自弃，一朝选在君王侧。\"\n",
    " \n",
    "def main():\n",
    "    body = urllib.parse.urlencode({'text':TEXT}).encode('utf-8')\n",
    "    param = {'type':'dependent'}\n",
    "    x_param = base64.b64encode(json.dumps(param).replace(' ', '').encode('utf-8'))\n",
    "    x_time = str(int(time.time()))\n",
    "    x_checksum = hashlib.md5(api_key.encode('utf-8') + str(x_time).encode('utf-8') + x_param).hexdigest()\n",
    "    x_header = {'X-Appid':x_appid,\n",
    "               'X-CurTime':x_time,\n",
    "               'X-Param':x_param,\n",
    "               'X-CheckSum':x_checksum}\n",
    "    req = urllib.request.Request(url, body, x_header)\n",
    "    result = urllib.request.urlopen(req)\n",
    "    result = result.read()\n",
    "    print(result.decode('utf-8'))\n",
    "    return\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用的相关NLP服务接口如下：\n",
    "* 中文分词(cws)  \n",
    "中文分词(Chinese Word Segmentation, CWS)指的是将汉字序列切分成词序列。因为在汉语中，词是承载语义的最基本的单元。分词是信息检索、文本分类、情感分析等多项中文自然语言处理任务的基础。  \n",
    "<br/> \n",
    "* 词性标注(pos)  \n",
    "词性标注(Part-of-speech Tagging, POS)是给句子中每个词一个词性类别的任务。这里的词性类别可能是名词、动词、形容词或其他。  \n",
    "<br/> \n",
    "* 命名实体识别(ner)  \n",
    "命名实体识别(Named Entity Recognition, NER)是在句子的词序列中定位并识别人名、地名、机构名等实体的任务。  \n",
    "<br/> \n",
    "* 依存句法分析(dp)  \n",
    "依存语法(Dependency Parsing, DP) 通过分析语言单位内成分之间的依存关系揭示其句法结构。直观来讲，依存句法分析识别句子中的“主谓宾”、“定状补”这些语法成分，并分析各成分之间的关系。  \n",
    "<br/> \n",
    "* 语义角色标注(srl)  \n",
    "语义角色标注(Semantic Role Labeling, SRL) 是一种浅层的语义分析技术，标注句子中某些短语为给定谓词的论元 (语义角色)，如施事、受事、时间和地点等。其能够对问答系统、信息抽取和机器翻译等应用产生推动作用。  \n",
    "<br/> \n",
    "* 语义依存 (依存树) 分析(sdp)  \n",
    "语义依存 (依存树) 分析(Semantic Dependency Parsing, SDP)，分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。使用语义依存刻画句子语义，好处在于不需要去抽象词汇本身，而是通过词汇所承受的语义框架来描述该词汇，而论元的数目相对词汇来说数量总是少了很多的。语义依存分析目标是跨越句子表层句法结构的束缚，直接获取深层的语义信息。  \n",
    "<br/> \n",
    "* 语义依存 (依存图) 分析(sdgp)  \n",
    "语义依存 (依存图) 分析(Semantic Dependency Graph Parsing, SDGP) 是在语义依存树基础上做了突破，使得对连动、兼语、概念转位等汉语中常见的现象的分析更全面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
